{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtreeviz\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, clear_output\n",
    "# from IPython.display.DisplayHandle import display, update\n",
    "# import IPython.display\n",
    "from math import ceil, sqrt\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.decomposition import PCA\n",
    "from ipywidgets import HBox, VBox, Layout, widgets\n",
    "from plotly.graph_objs import FigureWidget, Scatter, Table\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the Iris dataset\n",
    "# iris = datasets.load_iris()\n",
    "# df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "#                      columns= iris['feature_names'] + ['target'])\n",
    "df = pd.read_csv('data.csv')\n",
    "df.head()\n",
    "labels = pd.read_csv('labels.csv')\n",
    "df['label'] = labels['Class']\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2 (interactive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create histogram\n",
    "def create_histograms(df=df, exclude_cols=['target', '_x', '_y'], legend=True):\n",
    "    \"\"\"\n",
    "    Creates histograms of features in selected region and all data\n",
    "    ---\n",
    "    Input: Datafame\n",
    "    Output:\n",
    "        If dtreeviz_plot=True, then dtreeviz.utils.DTreeVizRender\n",
    "        Else, None\n",
    "    ---\n",
    "    df: Pandas Dataframe of data to analyze\n",
    "    exclude_cols: Columns not to plot (output and otherwise)\n",
    "    legend (default True): Whether to show legend on plots\n",
    "    \"\"\"\n",
    "    curr_df = df.drop(exclude_cols, axis=1)\n",
    "    r = int(sqrt(len(curr_df.columns)))\n",
    "    c = ceil(len(curr_df.columns) / r)\n",
    "    # fig = make_subplots(rows=r+1, cols=c+1, column_width=[1/c for _ in range(c + 1)], horizontal_spacing=0.2)\n",
    "    fig = make_subplots(rows=r+1, cols=c+1)\n",
    "    col_num =0\n",
    "    max_cols = len(df.columns)\n",
    "    for i in range(1, r+1):\n",
    "        for j in range(1, c+1):\n",
    "            if col_num < max_cols:\n",
    "                fig.add_trace(go.Histogram(x=curr_df[curr_df.columns[col_num]], name=curr_df.columns[col_num]), row=i, col=j) \n",
    "                fig.add_annotation(xref=\"x domain\",yref=\"y domain\",x=0.5, y=1.2, showarrow=False,\n",
    "                       text=f\"<b>{curr_df.columns[col_num]}</b>\", row=i, col=j)\n",
    "            col_num += 1\n",
    "    fig.update_layout(margin=dict(l=0, r=0, b=0))\n",
    "    fig.update_traces(showlegend=legend)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_cluster(df, x_cols, num_factors = 10, dtreeviz_plot=True):\n",
    "    \"\"\"\n",
    "    Runs decision tree on selected region and plots feature importance and decision boundaries\n",
    "    ---\n",
    "    Input: Pandas Datafame\n",
    "    Output:\n",
    "        If dtreeviz_plot=True, then dtreeviz.utils.DTreeVizRender\n",
    "        Else, None\n",
    "    ---\n",
    "    df: Pandas Dataframe of data to analyze\n",
    "    x_cols: Input columns of df\n",
    "    dtreeviz_plot: \n",
    "     - If True, plots decision tree of selection boundaries using dtreeviz library\n",
    "     - Else, plots decision tree of selection boundaries using sklearn (faster)\n",
    "    \"\"\"\n",
    "    # Split data into features and target\n",
    "    X = df[x_cols].values  # replace with the names of the columns you want to use as features\n",
    "    y = df['_selected'].values  # replace with the name of the target column you want to predict\n",
    "\n",
    "    # Create and fit a decision tree classifier\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    feature_importances = clf.feature_importances_\n",
    "    # Print the feature importances\n",
    "    # Combine feature names and importances into a list of tuples\n",
    "    feature_importances = list(zip(x_cols, feature_importances))\n",
    "\n",
    "    # Sort the list in descending order by feature importance\n",
    "    feature_importances_sorted = sorted(feature_importances, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Iterate over the sorted list and print out the feature names and importances\n",
    "    from ipywidgets import Output, VBox\n",
    "    print('Feature Importances in Decision Tree')\n",
    "    for feature_name, importance in feature_importances_sorted[:num_factors]:\n",
    "        importance_percent = importance * 100\n",
    "        print(f\"{feature_name}: {importance_percent:.2f}%\")   \n",
    "    if dtreeviz_plot:\n",
    "        viz_model = dtreeviz.model(clf,\n",
    "                               X_train=X, y_train=y,\n",
    "                               feature_names=x_cols,\n",
    "                               target_name=['_selected'], class_names=[\"not selected\", \"selected\"])\n",
    "        display(viz_model.view(scale=1.3))\n",
    "    else:\n",
    "        out = plot_tree(clf,\n",
    "           feature_names = x_cols,\n",
    "           class_names=['not selected', 'selected'],\n",
    "           filled = True)\n",
    "        out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_colors(df, label_col):\n",
    "#     # Using LabelEncoder to convert categories into numerical labels\n",
    "#     le = LabelEncoder()\n",
    "#     labels = le.fit_transform(df[label_col])\n",
    "#     # Define color palette (can be customized)\n",
    "#     cmap = mpl.colormaps['tab10']  # or any other colormap\n",
    "#     palette = [cmap(i) for i in np.linspace(0, 1, np.max(labels))]\n",
    "#     color = [palette[label] for label in labels]\n",
    "#     print(dict(color=mcolors.rgb2hex(df)))\n",
    "#     print(le.classes_)\n",
    "#     return dict(color=mcolors.rgb2hex(df))\n",
    "# get_colors(df, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colors(df, label_col):\n",
    "    \"\"\"\n",
    "    Generate a color mapping for distinct labels in a specified column of a DataFrame.\n",
    "    ---\n",
    "    Input: DataFrame, Label Column\n",
    "    Output: Dictionary mapping labels to colors\n",
    "    ---\n",
    "    df: Pandas DataFrame containing the data.\n",
    "    label_col: String specifying the column in the DataFrame that contains the labels to be colored.\n",
    "    \n",
    "    This function uses the LabelEncoder from sklearn to convert distinct labels in the specified column\n",
    "    to numerical values. It then generates a color for each distinct label using a matplotlib colormap.\n",
    "    The function returns a dictionary where the keys are the original labels and the values are the\n",
    "    corresponding colors in RGB hex format.\n",
    "    \"\"\"\n",
    "    # map categories into numerical labels\n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(df[label_col])\n",
    "    \n",
    "    cmap = mpl.colormaps['tab10'] \n",
    "    \n",
    "    # Generate a color for each unique label\n",
    "    # changed from .unique() approach, I think this should work\n",
    "    colors = cmap(np.linspace(0, 1, np.max(labels) +1))\n",
    "\n",
    "    # Convert colors to RGB hex format\n",
    "   # colors = [mcolors.rgb2hex(color) for color in colors]\n",
    "\n",
    "    color_map = dict(zip(le.classes_, colors))\n",
    "    \n",
    "    # Map each label in df[label_col] to its corresponding color\n",
    "    color_column = df[label_col].map(color_map)\n",
    "    \n",
    "    return dict(color=list(color_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lasso(df, mode='table', label_col=None, exclude_cols=[], num_factors = 10, dtreeviz_plot=True):\n",
    "    \"\"\"\n",
    "    Create Lasso tool to analyze lassoed data via below mode options\n",
    "    ---\n",
    "    Input: Datafame\n",
    "    Output: Plotly FigureWidget with lasso select tool\n",
    "    ---\n",
    "    data: Pandas Dataframe of data\n",
    "    exclude_cols: columns to exclude\n",
    "    mode:\n",
    "     - 'table' shows a table of selected points\n",
    "     - 'histogram' shows an interactive histogram selected points\n",
    "     - 'explainer' predicts which factors lead to clustered selection\n",
    "    dtreeviz_plot: \n",
    "     - If mode = 'explainer' and True, plots decision tree of selection boundaries using dtreeviz library\n",
    "     - Else, plots decision tree of selection boundaries using sklearn (faster)\n",
    "\n",
    "    \"\"\"\n",
    "    IS_HIST = mode == 'histogram'\n",
    "    TOP_FACTORS = mode == 'explainer'\n",
    "    s = widgets.Output()\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_cols = [x for x in df.columns if x not in exclude_cols]\n",
    "    included_cols_df = df[pca_cols]\n",
    "    pca.fit(included_cols_df)\n",
    "    pca_df = pd.DataFrame(pca.transform(included_cols_df), columns=['_x', '_y'])\n",
    "    df['_x'] = pca_df['_x']\n",
    "    df['_y'] = pca_df['_y']\n",
    "    \n",
    "    # !! TODO: fix color + None handling\n",
    "    color = None\n",
    "    if label_col is not None:\n",
    "        # https://stackoverflow.com/questions/68721086/plotly-how-to-define-marker-color-based-on-category-string-value-for-a-3d-scatt\n",
    "        f = FigureWidget([Scatter(y = df[\"_x\"], x = df[\"_y\"], mode = 'markers', marker=get_colors(df, 'label'))])\n",
    "\n",
    "    f = FigureWidget([Scatter(y = df[\"_x\"], x = df[\"_y\"], mode = 'markers')])\n",
    "    f.update_layout(dragmode='lasso')\n",
    "    f.layout.title = \"Data Lasso Scatterplot\"\n",
    "    scatter = f.data[0]\n",
    "    df.dropna()\n",
    "    exclude_cols.extend(['_x', '_y'])\n",
    "\n",
    "    N = len(df)\n",
    "    scatter.marker.opacity = 0.5\n",
    "    t = None\n",
    "    \n",
    "    if mode=='table':\n",
    "        # Create a table FigureWidget that updates on selection from points in the scatter plot of f\n",
    "        t = FigureWidget([Table(\n",
    "            header=dict(values=df.columns,\n",
    "                        fill = dict(color='#C2D4FF'),\n",
    "                        align = ['left'] * 5),\n",
    "\n",
    "            cells=dict(values=[df[col] for col in df.columns],\n",
    "                    fill = dict(color='#F5F8FF'),\n",
    "                    align = ['left'] * 5\n",
    "                    ))])\n",
    "    if IS_HIST:\n",
    "        hist = create_histograms(df, exclude_cols=exclude_cols, legend=True)\n",
    "        no_legend = create_histograms(df, exclude_cols=exclude_cols)\n",
    "        # t is for \"table\", but can also be where data is\n",
    "        t = go.FigureWidget(no_legend, )\n",
    "        t.layout.title = 'All Points'\n",
    "        # s is selected\n",
    "        s = go.FigureWidget(hist)\n",
    "        s.layout.title = 'Selected Points'\n",
    "    if TOP_FACTORS:\n",
    "        pass\n",
    "    def selection_fn(trace,points,selector):\n",
    "        nonlocal s\n",
    "        if mode=='table':\n",
    "            t.data[0].cells.values = [df.loc[points.point_inds][col] for col in df.columns]\n",
    "        if IS_HIST:\n",
    "            selected = df[df.index.isin(points.point_inds)]\n",
    "            new_charts = create_histograms(selected, exclude_cols=exclude_cols, legend=True)\n",
    "            s.data = []\n",
    "            s.add_traces(new_charts.data)\n",
    "        if TOP_FACTORS:\n",
    "            df['_selected'] = df.index.isin(points.point_inds)\n",
    "            x_cols = list(filter(lambda x: x not in exclude_cols and x != '_selected', df.columns))\n",
    "            with s:\n",
    "                clear_output(wait=True)\n",
    "            out = explain_cluster(df, x_cols, num_factors, dtreeviz_plot=dtreeviz_plot)    \n",
    "    scatter.on_selection(selection_fn)\n",
    "\n",
    "    # Put everything together\n",
    "    if IS_HIST:\n",
    "        return VBox((f, s, t), layout=Layout(align_items='flex-start', margin='0px', justify_content='center'))\n",
    "    return VBox(tuple(x for x in [f, s, t] if x))\n",
    "\n",
    "# create_lasso(mode='explainer', exclude_cols=['target'], dtreeviz_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2108c271318945588d34a19acf7d1b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FigureWidget({\n",
       "    'data': [{'marker': {'opacity': 0.5},\n",
       "              'mode': 'markers',\n",
       "     â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_lasso(df, mode='explainer', label_col='label', exclude_cols=['label'], dtreeviz_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add svm visualization - project the decision boundary down to 2d\n",
    "# - want PCA acconting for actual data and SVM line\n",
    "# - look at gene expression dataset\n",
    "# - later counterfactual explanations\n",
    "# - another idea: what if you have a graph and you select one dimension and PCA the other...\n",
    "# - could also add color as another dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clustering-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
